import torch
import json
import os
import requests
import re
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# ============================================================================
# é…ç½®
# ============================================================================
LOG_PATH = os.environ.get(
    "REWARD_LOG_PATH", 
    "/mnt/dolphinfs/ssd_pool/docker/user/hadoop-basecv-hl/hadoop-basecv/huangjing/proj/code/OpenRLHF/reward.log"
)
URL_MAPPING_PATH = "/mnt/dolphinfs/ssd_pool/docker/user/hadoop-basecv-hl/hadoop-basecv/huangjing/proj/code/OpenRLHF/data/result.json"

# å…¨å±€ç¼“å­˜ URL æ˜ å°„
_url_mapping_cache = None

# ä»£ç†é…ç½®
PROXIES = {
    'http': 'http://10.229.18.23:3128',
    'https': 'http://10.229.18.23:3128'
}

# æ¥å—çš„çŠ¶æ€ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
ACCEPTED_STATUSES = {'accept', 'accepted', 'ac'}

problem_pattern = r"<\|im_start\|>user\n(.*?)<\|im_end\|>"
response_prefix = r"<\|im_start\|>assistant\n"


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def load_url_mapping(force_reload: bool = False) -> Dict[str, str]:
    """åŠ è½½ URL æ˜ å°„é…ç½®"""
    global _url_mapping_cache
    
    if _url_mapping_cache is None or force_reload:
        try:
            with open(URL_MAPPING_PATH, 'r', encoding='utf-8') as f:
                _url_mapping_cache = json.load(f)
            print(f"âœ“ æˆåŠŸåŠ è½½ URL æ˜ å°„ï¼Œå…± {len(_url_mapping_cache)} ä¸ªé—®é¢˜")
        except FileNotFoundError:
            print(f"âš ï¸  è­¦å‘Š: URL æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨ - {URL_MAPPING_PATH}")
            _url_mapping_cache = {}
        except json.JSONDecodeError as e:
            print(f"âŒ é”™è¯¯: URL æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯ - {e}")
            _url_mapping_cache = {}
    
    return _url_mapping_cache

def get_response_from_query(q: str):
    ends_of_sentence = ["<|im_end|>", "<ï½œendâ–ofâ–sentenceï½œ>", "<|endoftext|>"]
    pos = re.search(response_prefix, q)
    if pos is None:
        return ""
    response = q[pos.end():]
    for e in ends_of_sentence:
        response = response.replace(e, "")
    return response.strip()

def extract_code_from_output(text: str) -> Optional[str]:
    """ä»æ¨¡å‹è¾“å‡ºä¸­æå–ä»£ç å—"""
    
    # æ–¹æ³•1: æå– Markdown ä»£ç å—ï¼ˆå¸¦è¯­è¨€æ ‡è®°ï¼‰
    pattern1 = r'```(?:cpp|c\+\+|c|python|java|javascript|go|rust)\s*\n(.*?)```'
    matches = re.findall(pattern1, text, re.DOTALL | re.IGNORECASE)
    
    if matches:
        code = matches[-1].strip()
        print(f"âœ“ æå–åˆ°ä»£ç å—ï¼ˆæ–¹æ³•1ï¼‰: {len(code)} å­—ç¬¦")
        return code
    
    # æ–¹æ³•2: æå–æ— è¯­è¨€æ ‡è®°çš„ä»£ç å—
    pattern2 = r'```\s*\n(.*?)```'
    matches = re.findall(pattern2, text, re.DOTALL)
    
    if matches:
        code = matches[-1].strip()
        print(f"âœ“ æå–åˆ°ä»£ç å—ï¼ˆæ–¹æ³•2ï¼‰: {len(code)} å­—ç¬¦")
        return code
    
    # æ–¹æ³•3: æŸ¥æ‰¾ #include å¼€å¤´çš„ C++ ä»£ç 
    pattern3 = r'(#include\s+<[^>]+>.*?)(?:\n\n[A-Z]|\Z)'
    matches = re.findall(pattern3, text, re.DOTALL)
    
    if matches:
        code = matches[-1].strip()
        print(f"âœ“ æå–åˆ°ä»£ç å—ï¼ˆæ–¹æ³•3ï¼‰: {len(code)} å­—ç¬¦")
        return code
    
    print("âš ï¸  æœªèƒ½æå–åˆ°ä»£ç å—")
    return None


def extract_problem_id(answer: str) -> str:
    """ä» answer ä¸­æå– problem_id"""
    if isinstance(answer, str) and '_' in answer:
        return answer.strip()
    
    try:
        answer_data = json.loads(answer)
        if isinstance(answer_data, dict):
            return answer_data.get('problem_id', '')
    except (json.JSONDecodeError, TypeError):
        pass
    
    match = re.search(r'(\d+_[A-Z])', answer)
    if match:
        return match.group(1)
    
    return ""


def calculate_reward(api_result: Dict) -> Tuple[float, str]:
    """æ ¹æ® API è¿”å›ç»“æœè®¡ç®— reward"""
    status = api_result.get('status', '').lower().strip()
    
    if status in ACCEPTED_STATUSES:
        return 1.0, f"âœ… Accepted ({status})"
    else:
        original_status = api_result.get('status', 'Unknown')
        return 0.0, f"âŒ {original_status}"


def get_reward_from_api(
    base_url: str, 
    problem_id: str, 
    code: str,  
    timeout: int = 600
) -> Tuple[float, Dict]:
    """é€šè¿‡ API è·å– reward"""
    try:
        url = f"{base_url}/api/submit/sync"
        
        data = {
            "problem_id": problem_id,
            "code": code,
            "language": 'c++17',
        }
        
        print(f"ğŸ”„ å‘é€è¯·æ±‚åˆ°: {url}")
        print(f"   Problem ID: {problem_id}")
        print(f"   Code length: {len(code)} chars")
        
        api_response = requests.post(
            url, 
            data=data,
            timeout=timeout,
            proxies=PROXIES,
        )
        
        api_response.raise_for_status()
        result = api_response.json()
        
        print(f"ğŸ“¥ API å“åº”:")
        print(f"   Status: {result.get('status', 'Unknown')}")
        print(f"   Score: {result.get('score', 0)}")
        
        reward, status_msg = calculate_reward(result)
        print(f"   Reward: {reward} - {status_msg}")
        
        # è¿”å›æ ‡é‡å€¼
        extra_info = {
            "status": "success",
            "judge_status": result.get('status', 'Unknown'),
            "score": float(result.get('score', 0)),
            "time_used": float(result.get('time_used', 0)),
            "memory_used": float(result.get('memory_used', 0)),
            "failed_case": float(result.get('failed_case', 0)),  # æ”¹ä¸º float
            "problem_id": problem_id,
            "submission_id": float(result.get('id', 0)),  # æ”¹ä¸º float
        }
        
        return reward, extra_info
        
    except requests.exceptions.Timeout:
        print(f"âš ï¸  API è¯·æ±‚è¶…æ—¶")
        return 0.0, {
            "status": "timeout", 
            "judge_status": "Timeout",
            "score": 0.0,
            "time_used": 0.0,
            "memory_used": 0.0,
            "failed_case": 0.0,
            "problem_id": problem_id,
            "submission_id": 0.0,
        }
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ API è¯·æ±‚å¤±è´¥: {e}")
        return 0.0, {
            "status": "error", 
            "judge_status": "Request Error",
            "score": 0.0,
            "time_used": 0.0,
            "memory_used": 0.0,
            "failed_case": 0.0,
            "problem_id": problem_id,
            "submission_id": 0.0,
        }
        
    except (ValueError, KeyError) as e:
        print(f"âŒ è§£æå“åº”å¤±è´¥: {e}")
        return 0.0, {
            "status": "parse_error", 
            "judge_status": "Parse Error",
            "score": 0.0,
            "time_used": 0.0,
            "memory_used": 0.0,
            "failed_case": 0.0,
            "problem_id": problem_id,
            "submission_id": 0.0,
        }


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def reward_func(queries, prompts, labels, **kwargs):
    """
    Reward function for calculating rewards of model outputs.
    
    Args:
        queries: æ¨¡å‹çš„å®Œæ•´è¾“å‡ºï¼ˆåŒ…å«ä»£ç ï¼‰
        prompts: è¾“å…¥æç¤º
        labels: æ ‡å‡†ç­”æ¡ˆï¼ˆproblem_idï¼‰
        
    Returns:
        dict: {
            "rewards": Tensor[batch_size],
            "scores": Tensor[batch_size],
            "extra_logs": Dict[str, Tensor[batch_size]]
        }
    """
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    url_mapping = load_url_mapping()
    
    batch_size = len(queries)
    
    # ğŸ”§ å…³é”®ï¼šä¸ºæ¯ä¸ªæ ·æœ¬æ”¶é›†æŒ‡æ ‡ï¼ˆåˆ—è¡¨ï¼‰
    rewards_list = []
    scores_list = []
    time_used_list = []
    memory_used_list = []
    failed_case_list = []
    submission_id_list = []
    
    # ç»Ÿè®¡ä¿¡æ¯
    status_counter = {}
    code_extraction_stats = {"success": 0, "failed": 0}
    
    print(f"ğŸ“ å¤„ç† {batch_size} ä¸ªæ ·æœ¬")
    print(f"ğŸ“ æ—¥å¿—è·¯å¾„: {LOG_PATH}")
    
    with open(LOG_PATH, "a", encoding='utf-8') as f:
        f.write(f"\n{'='*80}\n")
        f.write(f"Batch Evaluation - {current_time}\n")
        f.write(f"Batch Size: {batch_size}\n")
        f.write(f"{'='*80}\n\n")
        
        for idx, (query, prompt, answer) in enumerate(zip(queries, prompts, labels)):
            f.write(f"\n{'â”€'*80}\n")
            f.write(f"Sample {idx + 1}/{batch_size}\n")
            f.write(f"{'â”€'*80}\n")

            response = get_response_from_query(query)

            if not response:
                print(f"âš ï¸  æ ·æœ¬ {idx}: æœªèƒ½æå–åˆ° assistant å›å¤")
                rewards_list.append(0.0)
                continue
            
            # æå– problem_id
            problem_id = extract_problem_id(answer)
            
            if not problem_id:
                f.write(f"âŒ æ— æ³•æå– problem_id from answer: {answer}\n")
                rewards_list.append(0.0)
                scores_list.append(0.0)
                time_used_list.append(0.0)
                memory_used_list.append(0.0)
                failed_case_list.append(0.0)
                submission_id_list.append(0.0)
                status_counter["Invalid Problem ID"] = status_counter.get("Invalid Problem ID", 0) + 1
                continue
            
            f.write(f"Problem ID: {problem_id}\n")
            
            # æŸ¥æ‰¾å¯¹åº”çš„ base_url
            base_url = url_mapping.get(problem_id)
            
            if not base_url:
                f.write(f"âš ï¸  æœªæ‰¾åˆ° problem_id å¯¹åº”çš„ URL: {problem_id}\n")
                rewards_list.append(0.0)
                scores_list.append(0.0)
                time_used_list.append(0.0)
                memory_used_list.append(0.0)
                failed_case_list.append(0.0)
                submission_id_list.append(0.0)
                status_counter["URL Not Found"] = status_counter.get("URL Not Found", 0) + 1
                continue
            
            f.write(f"Base URL: {base_url}\n")
            
            # ä»è¾“å‡ºä¸­æå–ä»£ç 
            full_output = str(response).strip()
            code = extract_code_from_output(full_output)
            
            if code is None:
                f.write(f"âŒ æœªèƒ½ä»è¾“å‡ºä¸­æå–ä»£ç å—\n")
                code = full_output
                code_extraction_stats["failed"] += 1
            else:
                f.write(f"âœ“ æˆåŠŸæå–ä»£ç å—\n")
                code_extraction_stats["success"] += 1
            
            f.write(f"\n===full_output: \n{full_output}\n\n")
            f.write(f"Code length: {len(code)} chars\n")
            f.write(f"\n===Extracted Code:\n{code}\n\n")
            f.write(f"Code length: {len(code)} chars\n")
            f.write(f"Answer (Problem ID): {answer}\n\n")
            
            # è°ƒç”¨ API è·å– reward
            f.write(f"ğŸ”„ æ­£åœ¨è¯·æ±‚ API...\n")
            reward, extra_info = get_reward_from_api(
                base_url=base_url,
                problem_id=problem_id,
                code=code
            )
            
            f.write(f"âœ“ Reward: {reward}\n")
            f.write(f"Judge Status: {extra_info.get('judge_status', 'Unknown')}\n")
            f.write(f"Score: {extra_info.get('score', 0)}\n")
            f.write(f"Time Used: {extra_info.get('time_used', 0)} ms\n")
            f.write(f"Memory Used: {extra_info.get('memory_used', 0)} KB\n")
            
            # ğŸ”§ å…³é”®ï¼šæ”¶é›†æ¯ä¸ªæ ·æœ¬çš„å€¼
            rewards_list.append(reward)
            scores_list.append(extra_info['score'])
            time_used_list.append(extra_info['time_used'])
            memory_used_list.append(extra_info['memory_used'])
            failed_case_list.append(extra_info['failed_case'])
            submission_id_list.append(extra_info['submission_id'])
            
            # ç»Ÿè®¡çŠ¶æ€
            judge_status = extra_info.get('judge_status', 'Unknown')
            status_counter[judge_status] = status_counter.get(judge_status, 0) + 1
    
    # ğŸ”§ å…³é”®ï¼šè½¬æ¢ä¸º tensorï¼ˆç¡®ä¿æ˜¯ä¸€ç»´çš„ï¼‰
    rewards_tensor = torch.tensor(rewards_list, dtype=torch.float32)
    # scores_tensor = torch.tensor(scores_list, dtype=torch.float32)
    scores_tensor = torch.tensor(rewards_list, dtype=torch.float32)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    accepted_count = sum(1 for r in rewards_list if r > 0)
    avg_reward = sum(rewards_list) / batch_size if batch_size > 0 else 0
    success_rate = (accepted_count / batch_size * 100) if batch_size > 0 else 0
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Batch Evaluation Summary - {current_time}")
    print(f"{'='*80}")
    print(f"Total samples: {batch_size}")
    print(f"Accepted: {accepted_count} ({success_rate:.2f}%)")
    print(f"Average reward: {avg_reward:.4f}")
    print(f"\nä»£ç æå–ç»Ÿè®¡:")
    print(f"  æˆåŠŸ: {code_extraction_stats['success']}")
    print(f"  å¤±è´¥: {code_extraction_stats['failed']}")
    print(f"\nçŠ¶æ€åˆ†å¸ƒ:")
    for status, count in sorted(status_counter.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / batch_size * 100) if batch_size > 0 else 0
        print(f"  {status}: {count} ({percentage:.2f}%)")
    print(f"{'='*80}\n")
    
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šè¿”å›ç»“æ„
    # æ¯ä¸ª key å¯¹åº”ä¸€ä¸ª Tensor[batch_size]
    return {
        "rewards": rewards_tensor,  # shape: [batch_size]
        "scores": scores_tensor,    # shape: [batch_size]
        "extra_logs": {
            # âœ… æ¯ä¸ªå€¼éƒ½æ˜¯ Tensor[batch_size]
            "time_used": torch.tensor(time_used_list, dtype=torch.float32),      # [batch_size]
            "memory_used": torch.tensor(memory_used_list, dtype=torch.float32),  # [batch_size]
            "failed_case": torch.tensor(failed_case_list, dtype=torch.float32),  # [batch_size]
            "submission_id": torch.tensor(submission_id_list, dtype=torch.float32),  # [batch_size]
        }
    }


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æµ‹è¯• reward_func\n")
    
    # æµ‹è¯•ç”¨ä¾‹1: å•ä¸ªæ ·æœ¬
    test_query1 = """```cpp
#include <bits/stdc++.h>
using namespace std;

int main() {
    int n;
    cin >> n;
    cout << n << endl;
    return 0;
}
```"""
    
    # æµ‹è¯•ç”¨ä¾‹2: å¤šä¸ªæ ·æœ¬
    test_queries = [test_query1, test_query1]
    test_prompts = ['{"problem_id": "1220_B"}', '{"problem_id": "1220_B"}']
    test_labels = ["1220_B", "1220_B"]
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_queries)}\n")
    
    result = reward_func(test_queries, test_prompts, test_labels)
    
    print("\nğŸ¯ æµ‹è¯•ç»“æœ:")
    print(f"Rewards shape: {result['rewards'].shape}")
    print(f"Rewards: {result['rewards']}")
    print(f"\nScores shape: {result['scores'].shape}")
    print(f"Scores: {result['scores']}")
    print(f"\nExtra logs:")
    for key, value in result['extra_logs'].items():
        print(f"  {key}:")
        print(f"    shape: {value.shape}")
        print(f"    values: {value}")
    
    # éªŒè¯å½¢çŠ¶
    print("\nâœ… å½¢çŠ¶éªŒè¯:")
    batch_size = len(test_queries)
    assert result['rewards'].shape == torch.Size([batch_size]), f"rewards shape é”™è¯¯"
    assert result['scores'].shape == torch.Size([batch_size]), f"scores shape é”™è¯¯"
    for key, value in result['extra_logs'].items():
        assert value.shape == torch.Size([batch_size]), f"{key} shape é”™è¯¯"
    print("æ‰€æœ‰ tensor å½¢çŠ¶æ­£ç¡®ï¼")